# üß± dbt (Data Build Tool) ‚Äî Complete Guide for Data Engineers

---

## üåü 1Ô∏è‚É£ What is dbt?

**dbt (Data Build Tool)** is an open-source **data transformation framework** that enables **analytics engineers** to transform raw data in the **data warehouse** using **SQL and Jinja (templating)**.

It sits **after ingestion** (data already loaded into your warehouse from tools like Airflow, Fivetran, or Glue).

---

## ‚öôÔ∏è 2Ô∏è‚É£ Where dbt Fits in a Modern Data Stack

| Layer | Tool Example | Purpose |
|--------|----------------|----------|
| **Extract** | Fivetran, Airbyte, AWS Glue | Pull raw data into warehouse |
| **Load** | Snowflake COPY, Redshift COPY | Store raw data |
| **Transform (T in ELT)** | üß± **dbt** | Clean, join, and model data using SQL |
| **Visualize** | Looker, Tableau, Power BI | Consume clean data |

‚úÖ dbt turns your warehouse into a **version-controlled transformation engine**.

---

## üß© 3Ô∏è‚É£ Key dbt Concepts

| Concept | Description |
|----------|-------------|
| **Model** | A SQL file that defines a transformation (`SELECT` query). Output becomes a table/view. |
| **Project** | Folder containing all dbt code (models, tests, macros, configs). |
| **Source** | Declaration of raw data tables in the warehouse (e.g., staging tables). |
| **Seed** | CSV file loaded directly into the warehouse for static reference data. |
| **Test** | Assertions that ensure data quality (e.g., uniqueness, not null). |
| **Macro** | Reusable SQL or Jinja function. |
| **Snapshot** | Tracks slowly changing dimensions (historical changes in data). |
| **Run** | Executes dbt models in dependency order. |
| **Docs** | Auto-generates data lineage and documentation site. |

---

## üß† 4Ô∏è‚É£ How dbt Works (Under the Hood)

1Ô∏è‚É£ You write **SQL models** with Jinja templating.  
2Ô∏è‚É£ dbt compiles them into **pure SQL** (resolving dependencies).  
3Ô∏è‚É£ dbt executes these queries **inside your data warehouse** (Redshift, Snowflake, BigQuery, Databricks).  
4Ô∏è‚É£ The results are materialized as **tables or views**.

üí° dbt **doesn‚Äôt move data** ‚Äî it transforms data **already in the warehouse**.

---

## üß∞ 5Ô∏è‚É£ Installing & Initializing dbt

### Installation
```bash

pip install dbt-core dbt-redshift   # or dbt-snowflake, dbt-bigquery, etc.
```
### Create a New Project
``` bash

dbt init my_dbt_project
cd my_dbt_project

```

### Project Structure
``` bash
my_dbt_project/
‚îÇ
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_orders.sql
‚îÇ   ‚îú‚îÄ‚îÄ marts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fact_sales.sql
‚îÇ   ‚îî‚îÄ‚îÄ schema.yml
‚îî‚îÄ‚îÄ seeds/

```

## source
In dbt (data build tool), a source represents raw tables or views in your data warehouse that you do not manage with dbt ‚Äî i.e., tables that exist outside of dbt but that your models depend on.

Think of sources as the starting point of your transformations.

dbt encourages explicitly defining sources instead of directly referencing raw tables in SQL.

This improves documentation, testing, and lineage.

2Ô∏è‚É£ Benefits of using source

## Documentation & clarity

You can describe where the raw data comes from.

Others on your team know the upstream tables.

## Testing

dbt allows you to define tests on sources (like non-null or uniqueness).

## Lineage

Using sources makes your DAG in dbt docs clearer. You can see which models depend on which raw tables.

## Refactoring safety

If raw table names or schemas change, you only need to update the source definition, not every model SQL file.

## Syntax for defining a source

Sources are defined in schema.yml (or .yml) files inside your dbt project.

## Example:

Suppose you have a table raw_customers in the staging schema of your warehouse.

File structure:
```pgsql
dbt_project/
‚îú‚îÄ models/
‚îÇ  ‚îú‚îÄ staging/
‚îÇ  ‚îÇ  ‚îî‚îÄ customers.sql
‚îú‚îÄ models/
‚îÇ  ‚îî‚îÄ staging/schema.yml

```
```yaml
version: 2

sources:
  - name: staging       #source name
    database: your_database_name  # optional if dbt_project config handles it
    schema: staging
    tables:
      - name: raw_customers
        description: "Raw customers table from operational system"
        tests:
          - not_null:
              column_name: customer_id
          - unique:
              column_name: customer_id
```

### Referencing a source in a model
```sql
-- models/staging/customers.sql

WITH raw AS (
    SELECT *
    FROM {{ source('staging', 'raw_customers') }}
)

SELECT
    customer_id,
    first_name,
    last_name,
    email
FROM raw
WHERE email IS NOT NULL

```
### Explanation:

source('staging', 'raw_customers')

'staging' ‚Üí the source name defined in your schema.yml

'raw_customers' ‚Üí table name inside that source

### Adding tests on sources
```yaml
sources:
  - name: staging
    schema: staging
    tables:
      - name: raw_customers
        description: "Raw customers table"
        tests:
          - not_null:
              column_name: customer_id
          - unique:
              column_name: customer_id
          - relationships:
              column_name: customer_id
              to: ref('dim_customers')
              field: customer_id
```
not_null ‚Üí ensures customer_id has no nulls

unique ‚Üí ensures no duplicates

relationships ‚Üí checks foreign key relationship to another dbt model

### Example: Full dbt flow with source

Goal: Transform raw customers to cleaned customers.
```sql
WITH raw AS (
    SELECT *
    FROM {{ source('staging', 'raw_customers') }}
)

SELECT
    customer_id,
    first_name,
    last_name,
    LOWER(email) AS email,
    created_at
FROM raw
WHERE email IS NOT NULL
```
schema.yml
```yaml
version: 2

sources:
  - name: staging
    schema: staging
    tables:
      - name: raw_customers
        description: "Raw customers from ERP system"
        tests:
          - not_null:
              column_name: customer_id
          - unique:
              column_name: customer_id

models:
  - name: customers
    description: "Cleaned customers table"
    columns:
      - name: customer_id
        description: "Unique customer ID"
      - name: email
        description: "Customer email in lowercase"
```
### Run dbt commands:
```bash
dbt run
dbt test
dbt docs generate
dbt docs serve
```
### Key Best Practices
Always define sources in schema.yml rather than hardcoding raw table names.
Add meaningful descriptions for tables and columns ‚Äî improves dbt docs.
Test sources for nulls and uniqueness to catch upstream issues early.
Use source() in SQL, never hardcode database/schema/table in models.
Organize sources logically by schema or system name (staging, raw, marketing).

### Running dbt Commands
| Command                       | Description                            |
| ----------------------------- | -------------------------------------- |
| `dbt run`                     | Runs all models in dependency order    |
| `dbt test`                    | Runs data quality tests                |
| `dbt seed`                    | Loads static CSV data from `/seeds`    |
| `dbt docs generate`           | Builds documentation                   |
| `dbt docs serve`              | Opens documentation UI                 |
| `dbt compile`                 | Compiles SQL to target/compiled folder |
| `dbt run --select stg_orders` | Run specific model                     |
| `dbt run --full-refresh`      | Rebuild all tables/views               |


### dbt Tests (Data Quality)
### models/schema.yml
version: 2
```yaml
models:
  - name: stg_orders
    description: "Cleansed orders data"
    columns:
      - name: order_id
        tests:
          - not_null
          - unique
      - name: total_amount
        tests:
          - not_null

```
# Built-in tests: unique, not_null, accepted_values, relationships
### dbt Sources
Define your raw data tables:

```yaml
version: 2

sources:
  - name: raw
    schema: public
    tables:
      - name: orders
      - name: customers

```



